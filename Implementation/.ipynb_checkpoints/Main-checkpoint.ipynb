{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import DataReader as dr\n",
    "import Preprocessing\n",
    "import Analysis as anal\n",
    "import MinHash_Yan as mh_yan\n",
    "import MinHash as mh\n",
    "import MinHash_Riazzi as mh_riazzi\n",
    "import MinHash_Riazzi_ext as mh_riazzi_ext\n",
    "import MinHash_Yan_ext as mh_yan_ext\n",
    "#import test\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ['input_data/lastfm.dat']\n",
    "filename_JSim = 'input_data/lastfm_truth.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dr.read_data(filename)\n",
    "data_size = len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the actual Jaccard similarity of the data and write it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing.set_initial_JSim(data, data_size, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the actual Jaccard similarity of the data if this has already been calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSim = Preprocessing.set_JSim(data_size, filename_JSim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "algorithm = mh.MinHash(num_hashes, data)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riazzi et.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 10\n",
    "L = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "algorithm = mh_riazzi.sec_MinHash(numHashes, data, L)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yan et.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 10\n",
    "eps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "algorithm = mh_yan.LDP_JSE(num_hashes, data, eps)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riazi Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 10\n",
    "eps = 1\n",
    "L = 5\n",
    "not_dp_eps = 2\n",
    "diff_neighb_sets = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "algorithm = mh_riazzi_ext.sec_MinHash_ext(num_hashes, users, eps, L, not_dp_eps, diff_neighb_sets)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yan Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 10\n",
    "eps = 1\n",
    "num_buckets = data_size / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "algorithm = mh_yan_ext.LDP_JSE_ext(num_hashes, users, eps, num_buckets)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = anal.Analysis(user_to_sig, filename_JSim, filename_estJSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = analysis.MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, recall, f1 = analysis.PRF(JSim, est_JSim, neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('./JSims/Artificial_data_ground_truth')\n",
    "#directory = os.listdir()\n",
    "\n",
    "#print(os.getcwd())\n",
    "for file in directory:\n",
    "    open_file = open(file,'r')\n",
    "    lines = open_file.readlines()\n",
    "    #lines = lines[1:]\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        line = str(line.split('/t')[1:])\n",
    "        new_lines.append(line)\n",
    "    write_file = open(file, 'w')\n",
    "    write_file.writelines(new_lines)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate optimal number of hash functions in MinHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MinHash with varying number of hash functions, doubling each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numHashes = 10 #start 10\n",
    "limit_numHashes = 50 #1280\n",
    "precisions = []\n",
    "scale = 0.99\n",
    "nr_neighbours = 20\n",
    "mean_squared_errors = []\n",
    "hashes = []\n",
    "runs = 1 #100\n",
    "\n",
    "\n",
    "while numHashes <= limit_numHashes:\n",
    "    temp_prec = 0\n",
    "    temp_MSE = 0\n",
    "    for i in range(runs):\n",
    "        algorithm = mh.MinHash(numHashes, data)\n",
    "        user_to_sig = algorithm.generate_minHash_sigs()\n",
    "        est_JSim = anal.set_estJSim(algorithm, user_to_sig)\n",
    "        analysis = anal.Analysis(user_to_sig, JSim, est_JSim)\n",
    "        MSE = analysis.MSE()\n",
    "        prec, recall, f1 = analysis.PRF(nr_neighbours, scale)\n",
    "        temp_prec += prec \n",
    "        temp_MSE += MSE\n",
    "    precisions.append(temp_prec/runs)\n",
    "    mean_squared_errors.append(temp_MSE/runs)\n",
    "    hashes.append(numHashes)\n",
    "    print(numHashes)\n",
    "    numHashes += 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [hashes, precisions, mean_squared_errors]\n",
    "#ex.write_to_file('Ex_MinHash_50_to_200.txt', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes, precisions, mean_squared_errors, prec_ranges = ex.read_from_file('Ex_MinHash.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precisions)\n",
    "plt.plot(hashes, precisions)\n",
    "plt.axis([10,50,0,1])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('# of hashes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numHashes = 10 #start 10\n",
    "limit_numHashes = 100 #1280\n",
    "precisions = []\n",
    "prec_ranges = []\n",
    "threshold = 0.2\n",
    "mean_squared_errors = []\n",
    "hashes = []\n",
    "runs = 5 #100\n",
    "\n",
    "while numHashes <= limit_numHashes:\n",
    "    temp_prec = 0\n",
    "    temp_prec_range = 0\n",
    "    temp_MSE = 0\n",
    "    for i in range(runs):\n",
    "        algorithm = mh.MinHash(numHashes, data, next_prime)\n",
    "        user_to_sig = algorithm.generate_minHash_sigs()\n",
    "        est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "        analysis = anal.Analysis(user_to_sig, JSim, est_JSim)\n",
    "        MSE = analysis.MSE()\n",
    "        prec, recall, f1 = analysis.PRF(neighbours)\n",
    "        prec_range, recall_range, f1_range = analysis.prec_and_recall_and_F1(0.65)\n",
    "        temp_prec += prec\n",
    "        temp_prec_range += prec_range\n",
    "        temp_MSE += MSE\n",
    "    precisions.append(temp_prec/runs)\n",
    "    prec_ranges.append(temp_prec_range/runs)\n",
    "    mean_squared_errors.append(temp_MSE/runs)\n",
    "    hashes.append(numHashes)\n",
    "    print(numHashes)\n",
    "    numHashes += 10\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hashes, precisions)\n",
    "plt.axis([10,100,0,1])\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('# of hashes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average similarity and MinHash performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2d7df66e9920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mJSim_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSim_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mJSim_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_artificial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mJSim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_JSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJSim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mminHash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hashes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0muser_to_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminHash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_minHash_sigs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ITU/ITU_sem4/Thesis/Implementation/Preprocessing.py\u001b[0m in \u001b[0;36mset_JSim\u001b[0;34m(data_size, filename)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mJSims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mJSim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'JSIM matrix size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "numHashes = 100 #start 10\n",
    "scale = 0.99\n",
    "runs = 1 #100\n",
    "sim = [100, 1000, 10000, 100000]\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "MSE = []\n",
    "data_path = 'input_data/Artificial_data/'\n",
    "data_name = '_artificial_data.txt'\n",
    "JSim_path = 'JSims/Artificial_data_ground_truth/'\n",
    "JSim_name = '_artificial_data_truth.txt'\n",
    "\n",
    "\n",
    "for similarity in sim:\n",
    "    temp_prec = 0\n",
    "    temp_recall = 0\n",
    "    temp_f1 = 0\n",
    "    temp_MSE = 0\n",
    "    for i in range(runs):\n",
    "        data_file = data_path + str(similarity) + data_name\n",
    "        JSim_file = JSim_path + str(similarity) + JSim_name\n",
    "        data = dr.read_artificial_data(data_file)\n",
    "        JSim = Preprocessing.set_JSim(len(data),JSim_file)\n",
    "        minHash = mh.MinHash(data, num_hashes)\n",
    "        user_to_sig = minHash.generate_minHash_sigs()\n",
    "        est_JSim = anal.set_est_JSim(user_to_sig)\n",
    "        analysis = anal.Analysis(user_to_sig, JSim, est_JSim)\n",
    "        MSE = analysis.MSE()\n",
    "        prec, recall, f1 = analysis.PRF(nr_neighbours, scale)\n",
    "        temp_prec += prec\n",
    "        temp_recall += recall\n",
    "        temp_f1 += f1\n",
    "        temp_MSE += MSE\n",
    "    precisions.append(temp_prec/runs)\n",
    "    recalls.append(temp_recall/runs)\n",
    "    f1s.append(temp_f1/runs)\n",
    "    MSE.append(temp_MSE/runs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim, precisions)\n",
    "plt.axis([10,100000,0,1])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate optimal bit signature length in Riazzi et.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10  #start\n",
    "limit_l = 20\n",
    "optimal_k = 10 #need from 3.1 optimal nr of hash functions\n",
    "runs = 2\n",
    "\n",
    "all_ls = []\n",
    "precisions = []\n",
    "mean_squared_errors = []\n",
    "\n",
    "while l <= limit_l:\n",
    "    temp_prec = 0\n",
    "    temp_MSE = 0\n",
    "    for i in range(runs):\n",
    "        algorithm = mh_riazzi.sec_MinHash(numHashes, data, next_prime, l)\n",
    "        user_to_sig = algorithm.generate_minHash_sigs()\n",
    "        est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "        analysis = anal.Analysis(user_to_sig, JSim, est_JSim)\n",
    "        MSE = analysis.MSE()\n",
    "        prec, recall, f1 = analysis.PRF(neighbours)\n",
    "        temp_prec += prec\n",
    "        temp_MSE += MSE\n",
    "    precisions.append(temp_prec/runs)\n",
    "    mean_squared_errors.append(temp_MSE/runs)\n",
    "    all_ls.append(l)\n",
    "    print(l)\n",
    "    l = l * 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_ls, precisions)\n",
    "plt.axis([10,100,0,0.1])\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('length of bit-signature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate optimal shrinkage parameter for Yan et.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrink = 1  #start\n",
    "limit_shrink = 5\n",
    "eps = 1\n",
    "optimal_k = 10\n",
    "\n",
    "runs = 2 #100\n",
    "\n",
    "all_shrinks = []\n",
    "precisions = []\n",
    "mean_squared_errors = []\n",
    "\n",
    "while shrink <= limit_shrink:\n",
    "    temp_prec = 0\n",
    "    temp_MSE = 0\n",
    "    for i in range(runs):\n",
    "        algorithm = mh_yan.LDP_JSE(numHashes, data, next_prime, eps, shrink)\n",
    "        user_to_sig = algorithm.generate_minHash_sigs()\n",
    "        est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "        analysis = anal.Analysis(user_to_sig, JSim, est_JSim)\n",
    "        MSE = analysis.MSE()\n",
    "        prec, recall, f1 = analysis.PRF(neighbours)\n",
    "        temp_prec += prec\n",
    "        temp_MSE += MSE\n",
    "    precisions.append(temp_prec/runs)\n",
    "    mean_squared_errors.append(temp_MSE/runs)\n",
    "    all_shrinks.append(shrink)\n",
    "    print(shrink)\n",
    "    shrink  += 0.5    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performance between algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numHashes = 100 #wait and see\n",
    "l = 100\n",
    "# numHashes as colour?\n",
    "eps = 1\n",
    "shrink = 1.995\n",
    "flat_JSim = ex.matrix_to_list(JSim)\n",
    "est_JSims = []\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinHash\n",
    "algorithm = mh.MinHash(numHashes, data, next_prime)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "flat_est_JSim = ex.matrix_to_list(est_JSim)\n",
    "\n",
    "ex.write_to_file('MinHash_est_vs_JSim.txt', [flat_JSim, flat_est_JSim])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flat_est_JSim, flat_JSim)\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('est_JSim')\n",
    "plt.ylabel('JSim')\n",
    "plt.show()\n",
    "# make dots smaller\n",
    "# do regr line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yan\n",
    "algorithm = mh_yan.LDP_JSE(numHashes, data, next_prime, eps, shrink)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "\n",
    "flat_est_JSim = ex.matrix_to_list(est_JSim)\n",
    "\n",
    "ex.write_to_file('Yan_est_vs_JSim.txt', [flat_JSim, flat_est_JSim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flat_est_JSim, flat_JSim, s= 0.2)\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('est_JSim')\n",
    "plt.ylabel('JSim')\n",
    "plt.show()\n",
    "# make dots colored based on error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riazzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Riazzi\n",
    "algorithm = mh_riazzi.sec_MinHash(numHashes, data, next_prime, l)\n",
    "user_to_sig = algorithm.generate_minHash_sigs()\n",
    "est_JSim = algorithm.set_estJSim(user_to_sig)\n",
    "\n",
    "flat_est_JSim = ex.matrix_to_list(est_JSim)\n",
    "\n",
    "ex.write_to_file('Riazzi_est_vs_JSim.txt', [flat_JSim, flat_est_JSim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flat_est_JSim, flat_JSim, s= 0.2)\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('est_JSim')\n",
    "plt.ylabel('JSim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs. average similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of hash functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read_in = test.TestDataReadIn()\n",
    "test_read_in.test_MaxID()\n",
    "test_read_in.test_maxID_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jaccard = test.TestJaccard()\n",
    "test_jaccard.test_Jaccard()\n",
    "test_jaccard.test_est_Jaccard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "235px",
    "width": "238px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "493.6px",
    "left": "689px",
    "top": "141.8px",
    "width": "165.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
